{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re \n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a webdriver object and set options for headless browsing\n",
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome('./chromedriver',options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses webdriver object to execute javascript code and get dynamically loaded webcontent\n",
    "def get_js_soup(url,browser):\n",
    "    browser.get(url)\n",
    "    res_html = browser.execute_script('return document.body.innerHTML')\n",
    "    soup = BeautifulSoup(res_html,'html.parser') #beautiful soup object to be used for parsing html content\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ret = []\n",
    "    base_url = 'https://www.imdb.com'\n",
    "    soup = get_js_soup(dir_url,browser)     \n",
    "    if(soup.find_all('td',class_=\"result_text\") is None or soup.find_all('td',class_=\"result_text\") == []\n",
    "       or soup.find_all('td',class_=\"result_text\")[0].find('a')['href'] is None or soup.find_all('td',class_=\"result_text\")[0].find('a')['href'] == []):\n",
    "        return None\n",
    "    ret.append(base_url+soup.find_all('td',class_=\"result_text\")[0].find('a')['href'])\n",
    "    mainpage = ret[0]\n",
    "    soup2 = get_js_soup(mainpage,browser)\n",
    "\n",
    "    if(soup2.find_all(\"div\",class_ = \"poster\") is None or soup2.find_all(\"div\",class_ = \"poster\") == [] \n",
    "       or soup2.find_all(\"div\",class_ = \"poster\")[0].find(\"a\")[\"href\"] is None or soup2.find_all(\"div\",class_ = \"poster\")[0].find(\"a\")[\"href\"] == []):\n",
    "        return None\n",
    "    ret.append(base_url+soup2.find_all(\"div\",class_ = \"poster\")[0].find(\"a\")[\"href\"])\n",
    "\n",
    "    page3 = ret[1]\n",
    "    soup3 = get_js_soup(page3,browser)\n",
    "    \n",
    "    if(soup3.find_all(\"div\",class_ = \"pswp__item\") is None or soup3.find_all(\"div\",class_ = \"pswp__item\") == []\n",
    "       or soup3.find_all(\"div\",class_ = \"pswp__item\")[1].find_all(\"img\",class_ = \"pswp__img\")[1][\"src\"] is None\n",
    "      or soup3.find_all(\"div\",class_ = \"pswp__item\")[1].find_all(\"img\",class_ = \"pswp__img\")[1][\"src\"] == []):\n",
    "        return None\n",
    "\n",
    "    ret[1] = soup3.find_all(\"div\",class_ = \"pswp__item\")[1].find_all(\"img\",class_ = \"pswp__img\")[1][\"src\"]\n",
    "    \n",
    "    if(soup2.find(\"div\",class_ = \"ratingValue\") is None or soup2.find(\"div\",class_ = \"ratingValue\") == []\n",
    "       or soup2.find(\"div\",class_ = \"ratingValue\").find(\"strong\")[\"title\"] is None\n",
    "      or soup2.find(\"div\",class_ = \"ratingValue\").find(\"strong\")[\"title\"] == [] ):\n",
    "        return None\n",
    "    ret.append(soup2.find(\"div\",class_ = \"ratingValue\").find(\"strong\")[\"title\"].split()[0])\n",
    "    print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(query):\n",
    "    base = \"https://www.imdb.com/find?ref_=nv_sr_fn&q=\"\n",
    "    for i in query:\n",
    "        base+=i\n",
    "\n",
    "        base+=\"+\"\n",
    "\n",
    "    base+=\"&s=all\"\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_dir_page(generate_url([\"babe\"]),browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('data/combined_corpus_for_search_engine.csv')\n",
    "title = list(movie['Title'])\n",
    "\n",
    "list_ = []\n",
    "for i in title:\n",
    "    #title[i] = title[i].split()\n",
    "    url = generate_url(i.split())\n",
    "    list_.append(scrape_dir_page(url, browser))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
